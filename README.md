<div align="center">
  <img src="docs/images/blue_glass.png" alt="Blue Glass Logo" width="480"/>
</div>


# ğŸ”· Blue Glass

[![License](https://img.shields.io/badge/license-Apache_2.0-blue.svg)](LICENSE)
[![Hugging Face](https://img.shields.io/badge/dataset-Hugging%20Face-orange)](https://huggingface.co/)  

**Blue Glass** is an open-source framework for interpretability and analysis of vision-language and vision-only models. It empowers researchers and practitioners to understand what deep models *see* and *focus on* by offering tools to extract, probe, and build ad hoc XAI models for internal representations.


**Blue Glass** is an open-source framework for interpretability and analysis of vision-language and vision-only models. It empowers researchers and practitioners to understand what deep models see and attend to by providing tools to extract, probe, and build ad-hoc XAI models on internal representations.

The framework includes a custom infrastructure and lightweight modifications to third-party model libraries, enabling seamless feature extraction from the models. These extracted features are compiled into structured datasets called **Blue Glass-Lens**, laying the foundation for advanced Explainable AI research and experimentation.

---

## âœ¨ Key Features

- ğŸ“Š **Benchmarking & Probing**  
  Seamless support for benchmarking and probing internal representations at different model layers.
  
- ğŸ§  **Blue Glass-Lens Dataset**  
  A feature dataset generated by intercepting model activations via a custom interceptor called the **Feature Recorder**.

- ğŸ§ª **Ad-hoc Interpretability Models**  
  Leverage the Blue Glass-Lens dataset to train models like:
  - Linear Probes  
  - Sparse Autoencoders (SAEs)  
  - Other direct interpretability techniques  
  All optimized for **large batch sizes** and efficient performance.

- ğŸ§° **Generate Custom Blue Glass-Lens Dataset**  
  Use the built-in tools to generate your own **Blue Glass-Lens** dataset from any model.
 
- ğŸ” **Feature Patching & Re-Integration**  
  Ad-hoc models can be patched back into the base model using the **Feature Patcher**, enabling:  
  - Validation of interpretability methods  
  - Performance benchmarking of modified models

- ğŸš€ **Streamlined Runner**  
  A simplified, plug-and-play design built around modular runners and interfaces for training, validating, and evaluating ad-hoc models.

- âš™ï¸ **Scalable Training**  
  - Native support for **distributed training**  
  - Central control over **precision** (e.g., FP16, BF16)

- ğŸ” **Interpretability & Analysis**  
  Built for both **vision-language** and **vision-only** models with a focus on **clarity**, **transparency**, and **scalability**.

---

## ğŸ“¦ Coming Soon

- ğŸ“ˆ Visualization dashboard for Blue Glass-Lens datasets  
- ğŸ” Prebuilt probes for common models  
- ğŸ“š Tutorials and example notebooks

---

## ğŸ§ª Get Started

> Coming soon: Installation guide, usage examples, and API reference.

---

## ğŸ“– Detailed Documentation
#### [ğŸ› ï¸ BLUEGLASS Project Pipeline Overview](docs/project_execution_overview.md)
#### [ğŸ“Š Benchmarking Guide](docs/benchmarking.md)
#### [ğŸ§© Feature Extraction](docs/02_feature_extraction.md)
#### [ğŸ” Interpreter Tools](docs/03_interp_tools.md)
#### [ğŸ“‚ Dataset Handling and Management](docs/05_data_preparation.md)
#### [â–¶ï¸ Usage Guide](docs/usage_guide.md)

## ğŸ¤ Contributing

We welcome contributions! Feel free to open issues or submit pull requests to help expand the Blue Glass ecosystem.


---

